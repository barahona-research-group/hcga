{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 6: Loading data in different ways\n",
    "\n",
    "Here we provide some examples of data loading into hcga to provide some flexibility to the user.\n",
    "\n",
    "We focus here on loading into the graph collection object which is used by hcga.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "\n",
    "from hcga.graph import Graph, GraphCollection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading networkx graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a list of networkx graphs\n",
    "graph_1 = nx.karate_club_graph()\n",
    "graph_2 = nx.davis_southern_women_graph()\n",
    "graph_3 = nx.florentine_families_graph()\n",
    "\n",
    "# combine into list\n",
    "graphs = [graph_1, graph_2, graph_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = GraphCollection()\n",
    "gc.add_graph_list(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 graphs\n",
      "There graph ids are: [0, 1, 2]\n",
      "There are 0 features per node\n"
     ]
    }
   ],
   "source": [
    "print('There are {} graphs'.format(len(gc.graphs)))\n",
    "print('There graph ids are: {}'.format(gc.get_graph_ids()))\n",
    "print('There are {} features per node'.format(gc.get_n_node_features()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add another graph\n",
    "graph_4 = nx.les_miserables_graph()\n",
    "gc.add_graph(graph_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 graphs\n",
      "There are 0 features per node\n"
     ]
    }
   ],
   "source": [
    "print('There are {} graphs'.format(len(gc.graphs)))\n",
    "print('There are {} features per node'.format(gc.get_n_node_features()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading networkx graphs with node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a list of networkx graphs\n",
    "graph_1 = nx.karate_club_graph()\n",
    "graph_2 = nx.davis_southern_women_graph()\n",
    "graph_3 = nx.florentine_families_graph()\n",
    "\n",
    "# combine into list\n",
    "graphs = [graph_1, graph_2, graph_3]\n",
    "\n",
    "# node_features - two features: an all zeros feature and all ones feature\n",
    "node_features_graph_1 = np.array([np.zeros(len(graph_1)),np.ones(len(graph_1))]).T\n",
    "node_features_graph_2 = np.array([np.zeros(len(graph_2)),np.ones(len(graph_2))]).T\n",
    "node_features_graph_3 = np.array([np.zeros(len(graph_3)),np.ones(len(graph_3))]).T\n",
    "\n",
    "# combine node features into list\n",
    "node_features = [node_features_graph_1,node_features_graph_2,node_features_graph_3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = GraphCollection()\n",
    "gc.add_graph_list(graphs, node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 graphs\n",
      "There are 2 features per node\n"
     ]
    }
   ],
   "source": [
    "print('There are {} graphs'.format(len(gc.graphs)))\n",
    "print('There are {} features per node'.format(gc.get_n_node_features()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add another graph\n",
    "graph_4 = nx.les_miserables_graph()\n",
    "node_features_graph_4 = np.array([np.zeros(len(graph_4)),np.ones(len(graph_4))]).T\n",
    "gc.add_graph(graph_4, node_features_graph_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 graphs\n",
      "There are 2 features per node\n"
     ]
    }
   ],
   "source": [
    "print('There are {} graphs'.format(len(gc.graphs)))\n",
    "print('There are {} features per node'.format(gc.get_n_node_features()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading graphs with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a list of networkx graphs\n",
    "graph_1 = nx.karate_club_graph()\n",
    "graph_2 = nx.davis_southern_women_graph()\n",
    "graph_3 = nx.florentine_families_graph()\n",
    "\n",
    "# combine into list\n",
    "graphs = [graph_1, graph_2, graph_3]\n",
    "\n",
    "# define graph labels\n",
    "labels = [0,1,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = GraphCollection()\n",
    "gc.add_graph_list(graphs, graph_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 graphs\n",
      "There are 0 features per node\n"
     ]
    }
   ],
   "source": [
    "print('There are {} graphs'.format(len(gc.graphs)))\n",
    "print('There are {} features per node'.format(gc.get_n_node_features()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load numpy arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating some random numpy arrays as adjacency matrices\n",
    "graph_1 = np.random.randint(2, size=(10,10))\n",
    "graph_2 = np.random.randint(2, size=(10,10))\n",
    "graph_3 = np.random.randint(2, size=(10,10))\n",
    "\n",
    "\n",
    "# combine into list\n",
    "graphs = [graph_1, graph_2, graph_3]\n",
    "\n",
    "\n",
    "# node_features - two features: an all zeros feature and all ones feature\n",
    "node_features_graph_1 = np.array([np.zeros(len(graph_1)),np.ones(len(graph_1))]).T\n",
    "node_features_graph_2 = np.array([np.zeros(len(graph_2)),np.ones(len(graph_2))]).T\n",
    "node_features_graph_3 = np.array([np.zeros(len(graph_3)),np.ones(len(graph_3))]).T\n",
    "\n",
    "# combine node features into list\n",
    "node_features = [node_features_graph_1,node_features_graph_2,node_features_graph_3]\n",
    "\n",
    "# define graph labels\n",
    "labels = [0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = GraphCollection()\n",
    "gc.add_graph_list(graphs, node_features, graph_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 graphs\n",
      "There are 2 features per node\n"
     ]
    }
   ],
   "source": [
    "print('There are {} graphs'.format(len(gc.graphs)))\n",
    "print('There are {} features per node'.format(gc.get_n_node_features()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load directed graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating some random numpy arrays as adjacency matrices\n",
    "graph_1 = np.random.randint(2, size=(10,10))\n",
    "graph_2 = np.random.randint(2, size=(10,10))\n",
    "graph_3 = np.random.randint(2, size=(10,10))\n",
    "\n",
    "\n",
    "# combine into list\n",
    "graphs = [graph_1, graph_2, graph_3]\n",
    "\n",
    "\n",
    "# node_features - two features: an all zeros feature and all ones feature\n",
    "node_features_graph_1 = np.array([np.zeros(len(graph_1)),np.ones(len(graph_1))]).T\n",
    "node_features_graph_2 = np.array([np.zeros(len(graph_2)),np.ones(len(graph_2))]).T\n",
    "node_features_graph_3 = np.array([np.zeros(len(graph_3)),np.ones(len(graph_3))]).T\n",
    "\n",
    "# combine node features into list\n",
    "node_features = [node_features_graph_1,node_features_graph_2,node_features_graph_3]\n",
    "\n",
    "# define graph labels\n",
    "labels = [0,1,1]\n",
    "\n",
    "gc = GraphCollection()\n",
    "gc.add_graph_list(graphs, node_features, graph_labels=labels, graph_type='directed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 graphs\n",
      "There are 2 features per node\n"
     ]
    }
   ],
   "source": [
    "print('There are {} graphs'.format(len(gc.graphs)))\n",
    "print('There are {} features per node'.format(gc.get_n_node_features()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The graph type is: directed\n"
     ]
    }
   ],
   "source": [
    "print(' The graph type is: {}'.format(gc.graphs[0].graph_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving loaded dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save this if we want to and run everything from the command line\n",
    "from hcga.io import save_dataset\n",
    "save_dataset(gc, 'custom_dataset', folder='./datasets/custom_dataset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hcga.io import load_dataset\n",
    "gc = load_dataset(filename='./datasets/custom_dataset/custom_dataset.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
